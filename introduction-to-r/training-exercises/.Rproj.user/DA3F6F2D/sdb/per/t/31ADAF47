{
    "contents" : "---\ntitle: \"Introduction to R: Statistical Models Tutorial\"\nauthor: \"Dr Jeromy Anglim\"\noutput: pdf_document\n---\n\n```{r load_project, message = FALSE, warning = FALSE}\nlibrary(ProjectTemplate); load.project()\n\n# And create some variables\nlibrary(AER)\ndata(\"CASchools\")\n?CASchools\ncas <- CASchools\n\n# create new vaiables\n# academic performance as the sum of reading and mathematics\n# performance\ncas$performance <- as.numeric(scale(cas$read) + scale(cas$math))\n\n# student-staff ratio\ncas$student_teacher_ratio <- cas$students / cas$teachers\n\n# computers per student\ncas$computer_student_ratio <- cas$computer / cas$students \n\n# Student size is quite skewed\nhist(cas$students)\n# Let's log transform it\ncas$students_log <- log(cas$students)\nhist(cas$students_log)\n\n# same with average district income\ncas$income_log <- log(cas$income)\n\ndput(names(cas))\nv <- list()\n\nv$predictors <- \n    c(\"calworks\",     # percent of students qualifying for income assistance\n    \"lunch\",        # percent qualifying for reduced price lunch\n    \"expenditure\",  # expenditure per student\n    \"english\",      # percent of english learners\n    \"student_teacher_ratio\", \n    \"computer_student_ratio\", \n    \"students_log\", \n    \"income_log\")\nv$dv <- \"performance\"\nv$all_variables <- c(v$predictors, v$dv)\n```\n\n# Univariate statistics\n```{r}\n# sample size\nnrow(cas)\n\n# Frequencies or percentages on categorical variables\ntable(cas$grades) # frequency counts\nprop.table(table(cas$grades)) # proportions\n\n# Descriptive statistics for continuous variables\nround(psych::describe( cas[, v$all_variables]), 2)\n\n# Descriptive statistics for categorical and numeric variables\nHmisc::describe(cas)\n```\n\n\n# Bivariate correlations \n```{r}\ncor(cas[ , v$all_variables])\nround(cor(cas[ , v$all_variables]), 2) # round to 2 decimal places\nrp <- Hmisc::rcorr(as.matrix(cas[,v$all_variables])) # significance test on correlations\nrp\nifelse(rp$P < .05, \"*\", \"\")\n\n# Scatterplot matrix with correlations\npairs.panels(cas[ , v$all_variables])\n```\n\n\n# Regression models\n```{r}\n# By default, you don't get much output\nlm(performance ~ expenditure + calworks + lunch, data = cas)\n\n# You need to save the model to an object\nfit <- lm(performance ~ expenditure + calworks + lunch, cas)\n\n# this object stores the results of analyses.\n# You can extract elements directly from this object\nstr(fit) # show the structure of the object\nfit$coefficients\n\n# But more commonly you apply a set of \"methods\"\nsummary(fit) # summary info\npar(mfrow = c(2,2))\nplot(fit)\nanova(fit)\ninf <- influence.measures(fit) # various influence and outlier measures\n\nconfint(fit) # confidence intervals on coeficients\n\n# You can create plots yourself\n# Check normality and homoscedsaticity of residuals\n# plot predicted by residuals\nplot(predict(fit), residuals(fit))\nabline(h=0)\n\n# standardised coefficients\nlibrary(QuantPsyc)\nQuantPsyc::lm.beta(fit)\nfit_standardised <- lm(scale(performance) ~ scale(expenditure) + scale(calworks) + scale(lunch), cas)\nsummary(fit_standardised)\n\n# more information on regression diagnostics\n# http://www.statmethods.net/stats/rdiagnostics.html\n```\n\n# Comparing regression models\n```{r}\n# model 1 include poverty variables\nv$predictors\nfit1 <- lm(performance ~ calworks + lunch + expenditure + income_log, cas)\n# Model 2 adds school features\nfit2 <- lm(performance ~ calworks + lunch + expenditure + income_log +\n               student_teacher_ratio + students_log + \n               computer_student_ratio, cas)\n\nsummary(fit1)\nsummary(fit2)\n\n# Does second model explain significantly more variance?\nanova(fit1, fit2)\n```\n\n# Formula notation\n```{r}\n# For teaching purposes let's name the variables in a general way\nx <- cas[, c(\"performance\", \"student_teacher_ratio\", \"students_log\", \"income_log\")]\nhead(x)\nnames(x)  <- c(\"dv\", \"A\", \"B\", \"C\")\nhead(x)\n\n# Overview\n?formula\n# http://faculty.chicagobooth.edu/richard.hahn/teaching/FormulaNotation.pdf\n\n# 1 intercept\n# -1 exclude intercept\n# The intercept is included by default in linear models, \n# but in other contexts you need to specify it.\n\nlm(dv ~ A, x) # intercept included by default\nlm(dv ~ 1 + A, x) # intercept explicitly included (same as above)\nlm(dv ~ -1 + A, x) # exclude intercept\n\n# + main effect\nlm(dv ~ A + B, x) # main effect of A and B\n\n\n# * include interaction and main effects\n# : just main effect without interactions \nlm(dv ~ A * B, x) # main effects and interactions\nlm(dv ~ A:B, x) # no main effects but interaction\nlm(dv ~ A + B + A:B, x) # main effects explicitly specified\nlm(dv ~ A*B*C, x) # main effects, two-way interactions, three-way interaction\nlm(dv ~ (A + B + C)^3, x) # main as above\nlm(dv ~ (A + B + C)^2, x) # main effects but only two-way interactions\n\n# You can apply transformations to variables in place\nlm(dv ~ scale(A), x) # main effects but only two-way interactions\n# this is the same as creating a new variable\n# and using he new variable in the model\nx$zA <- scale(x$A)\nlm(dv ~ zA, x)\n\n# However if the transformation involves symbols that\n# have special meaning in the context of R formulas\n# i.e., +, -, *, ^, |, :\n# then you  # have to wrap it in the I()\n# I stands for Inhibit Interpretation or AsIs\n\n# Polynomial regression\nlm(dv ~ A + I(A^2), x) # include quadratic effect of A\nlm(dv ~ A + I(A^2) + I(A^3), x) # include quadratic and cubic effect of A\n\n# interaction effects with centering\nlm(dv ~ A + B + I(scale(A) * scale(B)), x) # z-score centre before creating interaction\n\n# composites\nlm(dv ~ I(A + B), x) # include the sum of two variables as a predictor\nlm(dv ~ I(2 * A + 5 * B), x) # include the weighted coposte as a predictor\n```\n\n\n# R Factors: Categorical predictors\n```{r}\n# Factors can be used for categorical variables\n\n# http://www.ats.ucla.edu/stat/r/modules/factor_variables.htm\nlibrary(MASS)\ndata(survey)\ncsurvey <- na.omit(survey)\n# let's assume a few variables were string variables\ncsurvey$Sex_character <- as.character(csurvey$Sex)\ncsurvey$Smoke_character <- as.character(csurvey$Smoke)\n\n# by default character variables will be converted to factors in regression models\nlm(Height ~ Sex_character, csurvey)\n# by default it performs dummy coding with the first category as the reference category\n# By default the ordering of a categorical variable is alphabetical\n\n# levels shows the levels of a factor variable\n# Thus, if we convert a sex as a character variable to a factor\n# F is before M to it is Female then Male\n\ncsurvey$Sex_factor <-  factor(csurvey$Sex_character)\nlevels(csurvey$Sex_factor)\nlm(Height ~ Sex_factor, csurvey)\n\n# Factors also influence the ordering of categorical variables\n# in plots\npar(mfrow=c(2,1))\nplot(Height ~ Sex_factor, csurvey) \n# and the order in tables\ntable(csurvey$Sex_factor)\n\n# If we wanted to change the order to Male then Female\ncsurvey$Sex_factor <- factor(csurvey$Sex_character, levels = c(\"Male\", \"Female\"))\nlevels(csurvey$Sex_factor)\nlm(Height ~ Sex_factor, csurvey) # now male is the reference category\nplot(Height ~ Sex_factor, csurvey) \ntable(csurvey$Sex_factor)\n\n\n# Ordered factors\n# Factors  \n# some factors reflect an ordinal relationship\n# e.g., survey frequency-agreement type scales\n# For example, see this smoking frequency items\ncsurvey$Smoke_factor <- factor(csurvey$Smoke)\ntable(csurvey$Smoke_factor)\n# By default it is in the wrong order\ncsurvey$Smoke_factor <- factor(csurvey$Smoke, c(\"Never\", \"Occas\", \"Regul\", \"Heavy\"))\ntable(csurvey$Smoke_factor)\n\n# However, we can also influence the type of contrasts performed\ncsurvey$Smoke_ordered <- factor(csurvey$Smoke, c(\"Never\", \"Occas\", \"Regul\", \"Heavy\"),\n                                ordered = TRUE)\n# or equivalently\ncsurvey$Smoke_ordered <- ordered(csurvey$Smoke, c(\"Never\", \"Occas\", \"Regul\", \"Heavy\"))\n\n# When included in linear model, we get\n# polynomial contrasts for ordered factors\nlm(Pulse ~ Smoke_ordered, csurvey)\n\n# Many data import functions have the option of\n# importing string variables as characters or factors\n# Some use a general configuration option:\nopt <- options()\nopt$stringsAsFactors\n# e.g., \n# read.table(..., stringsAsFactors = ...) \n# read.csv(..., stringsAsFactors = ...) \n\n# other functions have explicit options to import as factors\n# foreign::read.spss(..., use.value.labels = ...\n\n# Tip: My preference is to import string variables as character variables\n# If I want to use factors I prefer to explicitly create them.\n```\n\n# Exercise 1\n```{r exercise 1}\nlibrary(AER)\nhelp(package = AER)\ndata(\"GSS7402\")\n?GSS7402 # to learn about the dataset\n# It might be easier to work with a shorter variable name \n\n# 1. Run a t-test on whether participants who lived in a city\n#    at age 16 (i.e, city16) have more or less education \n#    than those those who did not\n\n# 2. Get correlations between education, number of kids (kids)\n#    year, and number of siblings (siblings)\n\n# 3. Run a multiple regresion predicting education from\n#    year, kids, and siblings.\n# 3.1 Run the model and save the fit\n\n# 3.2 Get a summary of the results\n\n# 3.3 the standardised coefficients\n\n# 3.4 Check whether the residuals are normally distributed\n\n# 3.5 Plot predicted values by residuals\n\n\n# 4. Factors\n# 4.1 create a table of values for ethnicity\n\n# 4.2 Run a regression predicting education from ethnicity\n\n# 4.3 Make a new factor variable where cauc is the reference value\n#     and check that this worked by running a regression with \n#     this new ethncity variable as the predictor.\n\n\n# 5. Comparing models\n# 5.1 Fit a model predicting education from \n#     (a) year and siblings \n#     (b) year, siblings, and the interaction\n#     and compare the fit of these two models\n\n```\n\n# Answers 1\n```{r answers 1}\nlibrary(AER)\nhelp(package = AER)\ndata(\"GSS7402\")\n?GSS7402 # to learn about the dataset\n# It might be easier to work with a shorter variable name \ngss <- GSS7402\n\n# 1. Run a t-test on whether participants who lived in a city\n#    at age 16 (i.e, city16) have more or less education \n#    than those those who did not\nt.test(education ~ city16, gss)\n\n# 2. Get correlations between education, number of kids (kids)\n#    year, and number of siblings (siblings)\ncor( gss[ ,c(\"education\", \"kids\", \"year\", \"siblings\")])\n\n\n# 3. Run a multiple regresion predicting education from\n#    year, kids, and siblings.\n# 3.1 Run the model and save the fit\nfit <- lm(education ~ year + kids + siblings, gss)\n\n# 3.2 Get a summary of the results\nsummary(fit)\n\n# 3.3 the standardised coefficients\nQuantPsyc::lm.beta(fit)\n\n# 3.4 Check whether the residuals are normally distributed\nhist(residuals(fit))\n\n# 3.5 Plot predicted values by residuals\nplot(predict(fit), residuals(fit), pch =\".\")\npar(mfrow = c(2, 2))\nplot(fit, pch=\".\")\npar(mfrow = c(1,1))\n\n\n# 4. Factors\n# 4.1 create a table of values for ethnicity\ntable(gss$ethnicity)\n\n# 4.2 Run a regression predicting education from ethnicity\nlm(education ~ ethnicity, gss)\n\n# 4.3 Make a new factor variable where cauc is the reference value\n#     and check that this worked by running a regression with \n#     this new ethncity variable as the predictor.\ngss$ethnicity_other <- factor( gss$ethnicity, c(\"cauc\", \"other\"))\nlm(education ~ ethnicity_other, gss)\n\n\n# 5. Comparing models\n# 5.1 Fit a model predicting education from \n#     (a) year and siblings \n#     (b) year, siblings, and the interaction\n# and compare the fit of these two models\nfit1 <- lm(education ~ year + siblings, gss)\nfit2 <- lm(education ~ year * siblings, gss)\nsummary(fit1)\nsummary(fit2)\nanova(fit1, fit2)\n```\n\n\n\n# Illustration of how ideas generalise to other kinds of models\n# Generalised linear models\n```{r}\n# Don't create median splits\n# but for the sake of example assume that we have\n# a binary outcome\ncas$high_performance <- as.numeric(cas$performance > median(cas$performance))\n\n# glm: generalised linear models\n# E.g., logistic regression\nfit <- glm(high_performance ~ calworks + lunch, cas, family = binomial())\nsummary(fit)\nexp(coef(fit)) # exp beta coefficients\n```\n\n# Multilevel modelling\n```{r}\n# Main multilevel modelling package\nlibrary(lme4) \n# also see older package\n# library(nlme)\n\n# Let's look at the built-in sleepstudy dataset\ndata(sleepstudy)\n?sleepstudy\n# long format dat\nhead(sleepstudy, 20)\n\ntable(sleepstudy$Subject) # number of observations per participant\nlength(table(sleepstudy$Subject)) # number of participants\ntable(sleepstudy$Days) # each participants observed at times 0 to 9\n\n# histogram of reaction time\nhist(sleepstudy$Reaction, 10)\n\n# Reaction time over days of sleep deprivation\n# each cell is one subject\nggplot(sleepstudy, aes(x = Days, y = Reaction)) + \n    geom_point() +\n    facet_wrap( ~ Subject)\n    \n\n# Random intercept\nfit1 <- lmer(Reaction ~ 1 + (1  | Subject),  data = sleepstudy)\n\n# Random intercept + fixed Days effect\nfit2 <- lmer(Reaction ~ 1 + Days + (1  | Subject),  data=sleepstudy) \n\n# Random intercept and random Days effect\nfit3 <- lmer(Reaction ~ 1 + Days + (1 + Days | Subject),  data=sleepstudy) \n\n# # Random intercept and linear Days effect, fixed quadratic Days effect\nfit4 <- lmer(Reaction ~ 1 + Days + I(Days^2) + (1 + Days | Subject),  data=sleepstudy) \n\n# Compare models\nanova(fit1, fit2)\nanova(fit2, fit3)\nanova(fit3, fit4)\n\n# Summary of best fitting model\nsummary(fit3)\n\n# Most standard methods from lm also apply\nplot(fit3) # plot fitted by residuals\nhist(residuals(fit3)) # histogram of residuals\n\n# Save and plot predicted values\nsleepstudy$predicted_fit3 <- predict(fit3)\nggplot(sleepstudy, aes(x = Days, y = Reaction)) + \n    geom_point() + geom_line(aes(y=predicted_fit3))  +\n    facet_wrap( ~ Subject)\n```\n\n# Exercise 2\n```{r exercise 2}\n# Let's create some simulated data with a random intercept\n# and random slope.\nset.seed <- 1234 # ensures we get the same results\nsim <- expand.grid(subject = 1:20, time = 1:10)\nsim_subject <- data.frame(subject = 1:20, \n                     intercept = rnorm(20, 0, 1),\n                     beta = rnorm(20, .3, .2))\nsim <- merge(sim, sim_subject)\nsim$dv <- rnorm(nrow(sim),  sim$intercept + sim$beta * sim$time,  .6)\n\n# 1. Plot the the effect of the dv by time over subjects\n\n# 2. Fit models predicting dv from time by subject\n#    (1) a random intercept model\n#    (b) a random intercept plus fixed slope model\n#    (c) a rndom intercept and random slope model\n\n# 3. Get summary information for model 3\n\n# Compare the fits of the three models\n# which is best?\n    \n```\n\n# Answers\n```{r answers for exercise 2}\n# Let's create some simulated data with a random intercept\n# and random slope.\nsset.seed <- 1234 # ensures we get the same results\nsim <- expand.grid(subject = 1:20, time = 1:10)\nsim_subject <- data.frame(subject = 1:20, \n                     intercept = rnorm(20, 0, 1),\n                     beta = rnorm(20, .3, .2))\nsim <- merge(sim, sim_subject)\nsim$dv <- rnorm(nrow(sim),  sim$intercept + sim$beta * sim$time,  .6)\n\n# 1. Plot the the effect of the dv by time over subjects\nggplot(sim, aes(x = time, y = dv)) + \n    geom_point() + facet_wrap( ~ subject)\n\n\n# 2. Fit models predicting dv from time by subject\n#    (1) a random intercept model\n#    (b) a random intercept plus fixed slope model\n#    (c) a rndom intercept and random slope model\n\nfit1 <- lmer(dv ~ 1 + (1  | subject),  data = sim)\nfit2 <- lmer(dv ~ 1 + time + (1  | subject),  data=sim) \nfit3 <- lmer(dv ~ 1 + time + (1 + time | subject),  data=sim) \n\n# 3. Get summary information for model 3\nsummary(fit3)\n\n# Compare the fits of the three models\n# which is best\nanova(fit1, fit2)\nanova(fit2, fit3) # model 3 is best\n```\n\n\n# Structural equation modelling\n```{r}\n# There are three main options for SEM\n# library(sem): this is the original one\n#\n# library(OpenMx): Very powerful but more complicated\n# http://openmx.psyc.virginia.edu/\n#\n# library(lavaan): \n# This is my first choice when it comes to doing\n# all the standard things that you might do in a program like Amos \n# Lots of user friendly documentation on:\n# http://lavaan.ugent.be/\n# I also have a cheat sheet\n# http://jeromyanglim.tumblr.com/post/33556941601/lavaan-cheat-sheet\n\nlibrary(lavaan)\nlibrary(psych)\ndata(bfi)\n\ncbfi <- na.omit(bfi)\n\ndim(cbfi)\nhead(cbfi)\ndput(names(cbfi))\nv$sem <- c(\"A1\", \"A2\", \"A3\", \"A4\", \"A5\", \"C1\", \"C2\", \"C3\", \"C4\", \"C5\", \n    \"E1\", \"E2\", \"E3\", \"E4\", \"E5\", \"N1\", \"N2\", \"N3\", \"N4\", \"N5\", \"O1\", \n    \"O2\", \"O3\", \"O4\", \"O5\")\n\n# Exploratory factor analysis\n# Extract 5 factors with promax rotation \npsych::scree(cbfi[ v$sem]) # scree plot\nfa <- factanal(cbfi[ v$sem], factors = 5, rotation = \"promax\") \nprint(fa, cutoff=.3) # print results hiding loadings below .3\n\n# Confirmatory factor analysis\n# Write out SEM using model notation\nmodel1 <- \"\n    # latent variable definitions\n    # side point: first item gets loading of 1 so\n    # it is clearer if this is a positively worded item\n    agreeableness =~ A2 + A1 + A3 + A4 + 1 * A5\n    conscientiousnes =~ C1 + C2 + C3 + C4 + C5\n    extraversion =~ E3 + E1 + E2  + E4 + E5\n    neuroticism =~ N1 + N2 + N3 + N4 + N5\n    openness =~  O1 + O2 + O3 + O4 + O5\n\"\n\n# fit model\nfit1 <- cfa(model1, data=cbfi[ v$sem])\nsummary(fit1, fit.measures=TRUE)\n\n# Suggest modifications\nmod_ind <- modificationindices(fit1)\nsplit(head(mod_ind[order(mod_ind$mi, decreasing=TRUE), ], 20), \n      head(mod_ind[order(mod_ind$mi, decreasing=TRUE), \"op\"], 20))\n\n\n# Refine model\nmodel2 <- \"\n    # latent variable definitions\n    # side point: first item gets loading of 1 so\n    # it is clearer if this is a positively worded item\n    agreeableness =~ A2 + A1 + A3 + A4 + 1 * A5\n    conscientiousnes =~ C1 + C2 + C3 + C4 + C5\n    extraversion =~ E3 + E1 + E2  + E4 + E5\n    neuroticism =~ N1 + N2 + N3 + N4 + N5\n    openness =~  O1 + O2 + O3 + O4 + O5\n\n    # add some correlated items that are very similar\n    N1 ~~ N2\n    N3 ~~ N4\n    C1 ~~ C2\n\"\n\nfit2 <- cfa(model2, data=cbfi[ v$sem])\nsummary(fit2, fit.measures=TRUE)\n\nff1 <- fitMeasures(fit1)\nff2 <- fitMeasures(fit2)\nff1\n\n# show measures you want\ndput(names(ff1))\nv$stats <-  c(\"npar\", \"chisq\", \"df\", \"pvalue\", \n   \"cfi\", \"rmsea\", \"rmsea.ci.lower\", \"rmsea.ci.upper\")\n\n# compare stats\nround(data.frame(ff1[v$stats],  ff2[v$stats]), 3)\n```\n\n\n# Meta analysis\n```{r}\n# Lots of meta-analysis options\n# http://cran.r-project.org/web/views/MetaAnalysis.html\n# meta, rmeta, and metafor are all fairly general meta-analysis packages\nlibrary(metafor)\n\n# Example is based on \n# http://www.metafor-project.org/doku.php/analyses:normand1999\ndata(\"dat.normand1999\")\n?dat.normand1999\n# compares mean length of stay for stroke patients\n# in speialised care (group 1) and routine care (group 2)\ndat.normand1999\nmean(dat.normand1999$m1i) # mean over studies length of time in specialised care\nmean(dat.normand1999$m2i) # ...........                      in routine care\n\n# calculate pooled standard deviation\ndat.normand1999$sdpi <- with(dat.normand1999, \n                             sqrt(((n1i - 1) * sd1i^2 + (n2i - 1) * sd2i^2) /\n                                      (n1i + n2i - 2)))\n# Compare standard mean differences\ndat <- escalc(m1i=m1i, sd1i=sdpi, n1i=n1i, m2i=m2i, sd2i=sdpi, n2i=n2i,\n              measure=\"SMD\", data=dat.normand1999, digits=2)\n# Fit random effects meta analysis\nfit <- rma(yi, vi, data=dat, method=\"HS\", digits=2)\nsummary(fit) # Estimate of mean and sd of effect\nforest(fit) # Plot of effect size estimates\n```\n\n\n\n# Bootstrapping\n```{r}\nlibrary(boot)\n# see also\n# http://www.statmethods.net/advstats/bootstrapping.html\n\n\nlibrary(car)\n# Use height and weight data of university students\ndata(Davis)\nDavis <- na.omit(Davis)\nDavis$bmi <- with(Davis, weight/(height/100)^2)\nhist(Davis$bmi)\n# looks like data entry error\nDavis[ Davis$bmi > 100, ]\n# let's remove and work with cleaned data\ncdavis <-  Davis[ Davis$bmi < 100, ]\n\n# Which correlation is larger\n# Correlation between actual and report height \n# or correlation between actual and reported weight\npar(mfrow=c(2,1))\nplot(cdavis$height, cdavis$repht)\nabline(a = 0, b = 1)\nplot(cdavis$weight, cdavis$repwt)\nabline(a = 0, b = 1)\n\n\n# look at sample data\n# correlation for weight looks a tiny bit bigger\n# but is it significant\ncor(cdavis$height, cdavis$repht)\ncor(cdavis$weight, cdavis$repwt)\n\n# How could we test this using a bootstrap?\n\n# function receives\ncordif <- function(data, i) {\n    cidavis <- data[i, ]\n    cor1 <- cor(cidavis$height, cidavis$repht)\n    cor2 <- cor(cidavis$weight, cidavis$repwt)\n    cor1 - cor2\n}\n\nfit <- boot(data = cdavis, statistic = cordif, R = 2000)\nfit\nboot.ci(fit)\n```\n\n\n\n# Bayesian modelling\n```{r}\n# See interfaces with Bayesian modelling language like\n# library(rjags)  # JAGS\n# and\n# library(rstan) # Stan\n#\n# See example project:\n# Anglim, J., & Wynton, S. K. (2015). Hierarchical Bayesian Models of \n# Subtask Learning. Journal of experimental psychology. Learning, memory, and cognition.\n# Full repository with R code available at\n# https://github.com/jeromyanglim/anglim-wynton-2014-subtasks\n```\n\n",
    "created" : 1467782035193.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3325495562",
    "id" : "31ADAF47",
    "lastKnownWriteTime" : 1435108518,
    "path" : "~/teaching/r-training/training-materials/training-exercises/3-statistical-models.rmd",
    "project_path" : "3-statistical-models.rmd",
    "properties" : {
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_markdown"
}